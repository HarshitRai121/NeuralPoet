{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdO+4zEtYf6R0KEK1Ztn/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshitRai121/NeuralPoet/blob/main/NeuralPoetModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddBocthNrQEx"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.layers import Activation, Dense, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = tf.keras.utils.get_file('shakespeare.txt',\n",
        "        'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')\n",
        "text = open(filepath, 'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNuPapZYrZda",
        "outputId": "2c526133-78d2-4987-9df6-d194cdd271a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text[300000:800000]"
      ],
      "metadata": {
        "id": "E_diz2Qorfui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "characters = sorted(set(text))\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(characters))\n",
        "index_to_char = dict((i, c) for i, c in enumerate(characters))"
      ],
      "metadata": {
        "id": "hfkw3SrBrmKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LENGTH = 40\n",
        "STEP_SIZE = 3\n",
        "\n",
        "sentences = []\n",
        "next_char = []"
      ],
      "metadata": {
        "id": "roRGAvoarqQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(text) - SEQ_LENGTH, STEP_SIZE):\n",
        "    sentences.append(text[i: i + SEQ_LENGTH])\n",
        "    next_char.append(text[i + SEQ_LENGTH])"
      ],
      "metadata": {
        "id": "4kauojI_rvDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(sentences), SEQ_LENGTH,\n",
        "              len(characters)), dtype=bool)\n",
        "y = np.zeros((len(sentences),\n",
        "              len(characters)), dtype=bool)\n",
        "\n",
        "for i, satz in enumerate(sentences):\n",
        "    for t, char in enumerate(satz):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "    y[i, char_to_index[next_char[i]]] = 1"
      ],
      "metadata": {
        "id": "CQnE_qmnrzu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128,\n",
        "               input_shape=(SEQ_LENGTH,\n",
        "                            len(characters))))\n",
        "model.add(Dense(len(characters)))\n",
        "model.add(Activation('softmax'))"
      ],
      "metadata": {
        "id": "b-7TzXSusPEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.01))\n",
        "\n",
        "model.fit(x, y, batch_size=256, epochs=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFw_FUwWsUUs",
        "outputId": "1497f028-cefd-4272-9bb2-3e30700688e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "651/651 [==============================] - 119s 179ms/step - loss: 2.9054\n",
            "Epoch 2/4\n",
            "651/651 [==============================] - 117s 180ms/step - loss: 2.3719\n",
            "Epoch 3/4\n",
            "651/651 [==============================] - 117s 180ms/step - loss: 2.2255\n",
            "Epoch 4/4\n",
            "651/651 [==============================] - 118s 181ms/step - loss: 2.1364\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78bfa4362da0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "metadata": {
        "id": "-8qVEdw4uPR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(length, temperature):\n",
        "    start_index = random.randint(0, len(text) - SEQ_LENGTH - 1)\n",
        "    generated = ''\n",
        "    sentence = text[start_index: start_index + SEQ_LENGTH]\n",
        "    generated += sentence\n",
        "    for i in range(length):\n",
        "        x_predictions = np.zeros((1, SEQ_LENGTH, len(characters)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_predictions[0, t, char_to_index[char]] = 1\n",
        "\n",
        "        predictions = model.predict(x_predictions, verbose=0)[0]\n",
        "        next_index = sample(predictions,\n",
        "                                 temperature)\n",
        "        next_character = index_to_char[next_index]\n",
        "\n",
        "        generated += next_character\n",
        "        sentence = sentence[1:] + next_character\n",
        "    return generated"
      ],
      "metadata": {
        "id": "_pcLooASuUMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFIt_gmFuciv",
        "outputId": "d15e0772-8633-48b2-e6b8-0d95e6ae5ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "' speak any thing against me, I'll take the wall.\n",
            "\n",
            "RING IOR:\n",
            "And the the the with the dather the will thee the fore.\n",
            "\n",
            "RONG OOR:\n",
            "I the the lound with the the the pare the weath.\n",
            "\n",
            "RONG ION:\n",
            "What the wich the with the the cound the soure.\n",
            "\n",
            "KING HARD II:\n",
            "And whith the the sour of the sour the fore.\n",
            "\n",
            "KING RIARD:\n",
            "Wher the the be the fore the po\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_vjeMF2ukuT",
        "outputId": "2bad27e0-3390-4302-c2ea-6b65222a2371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARWICK:\n",
            "Then, for his mind, be Edward not the me.\n",
            "\n",
            "AUENT:\n",
            "O the gome to doustoren and the my the thes,\n",
            "And lave wist the werthe to the toon the eather.\n",
            "\n",
            "KONG HERD I:\n",
            "The fore the fullee the sound the and and where.\n",
            "\n",
            "WhURI IO:\n",
            "Whell thee her the the pove the seat the our\n",
            "And or you the then the de the mere the tore.\n",
            "\n",
            "INGEOT:\n",
            "And rof, gea\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LctXegKWuvAC",
        "outputId": "48ea4daf-279c-40e4-d1dd-901ac5e95563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "erto goes well;\n",
            "The common people by numy to the ward of the weath\n",
            "And my and what out that thou dat the sount.\n",
            "\n",
            "ALETES:\n",
            "What, nit cereith the dead he the and to fore!\n",
            "And and word you dhe the then stound,\n",
            "No the my all ond hith and the oun the love\n",
            "To my fore ast me were the keat the oferes\n",
            "And shear ous the day the be the me mering out\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.6))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkI3aktwu5qN",
        "outputId": "14e42e99-70e9-44fd-9764-079711cb58a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "of your young prince as we\n",
            "Do seem to be the herpente you thees thee,\n",
            "I thinest the oudse the my hamy wat on thoundersent.\n",
            "\n",
            "KARD IO:\n",
            "Whal wing stist roses in the guede, thie beath.\n",
            "\n",
            "DARD IF INBAREN:\n",
            "The or the seathy, to be thinge thee and hes and beather,\n",
            "Soun ol, and afr hall sand:\n",
            "I hemele this bive the fof his in saye,\n",
            "And patt.\n",
            "Thes \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(300, 0.7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI69zm1nvF7A",
        "outputId": "a80e30f6-2aff-48c1-f340-6ad43a0d1071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traitor rear?\n",
            "\n",
            "DUCHESS OF YORK:\n",
            "Sweet Yow my sathie with the What sean,\n",
            "The pose to then that she hach ef iom in stouch,\n",
            "My and me stourtoun the me thementee werse.\n",
            "\n",
            "MENCSY:\n",
            "Whyt miad urcmorke, lores, chatinoin preath;\n",
            "Youn to meath you fringe mangot onding.\n",
            "\n",
            "DAMLIR:\n",
            "I ard I wound we be ix now thou dowerowe,\n",
            "The and suold a ndond, theer w\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_text(500, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5icg8sVdvsvW",
        "outputId": "c9caa0cf-a220-44f4-83d4-bf39907ddcf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o the hilt\n",
            "In blood of those that had entlend bee,\n",
            "\n",
            "Daprs mee:\n",
            "Oy unet, whape bothel ruegh erteng:\n",
            "tu ta dess andatht pest yous, lor buve! Fapl:\n",
            "Thistelt vey -nid th to at hing featy Oace.\n",
            "\n",
            "RUOTE:\n",
            "Nhou hath thest the meaie ady of preness\n",
            "Dod ure woll, ind coke to is ane fallasawinge.\n",
            "Boud ind aflak in wour. day hecl fonher?\n",
            "Th,\n",
            "Bines neurdl amyde they fraythome:\n",
            "Or, rous Wot yous ow the siel's te turte.\n",
            "An tho joed thenge thes enou theoke,\n",
            "Thoul kat? were's ferest sty llysmute, not ib mare,\n",
            "'e iplithe's and inoment wot I wirk aid.\n",
            "\n",
            "AR\n"
          ]
        }
      ]
    }
  ]
}